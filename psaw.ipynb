{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psaw\n",
    "from psaw import PushshiftAPI\n",
    "api = PushshiftAPI()\n",
    "import pandas as pd\n",
    "import praw\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"wBlYlJ7XtNtL0d1fEAj-vg\",\n",
    "    client_secret=\"muW07OSaCr5I4Dj23Sn7HeFeoifSLg\",\n",
    "    user_agent=\"a12487\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = api.search_comments(author='nasa', aggs='subreddit')\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.metadata_.get('shards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gen = api.search_comments(q='ub82Xb1C8os|dQw4w9WgXcQ',filter=['subreddit','body','permalink','created_utc']limit=10000)\n",
    "max_response_cache = 1000\n",
    "cache = []\n",
    "x=0\n",
    "for c in gen:\n",
    "    x+=1\n",
    "    print(x)\n",
    "    cache.append(c)\n",
    "    # Omit this test to actually return all results. Wouldn't recommend it though: could take a while, but you do you.\n",
    "    if len(cache) >= max_response_cache:\n",
    "        break\n",
    "\n",
    "# If you really want to: pick up where we left off to get the rest of the results.\n",
    "if False:\n",
    "    for c in gen:\n",
    "        cache.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cache),x)\n",
    "data = []\n",
    "for x in cache :\n",
    "    data.append([x.body,x.subreddit,x.created_utc])\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "x = pd.DataFrame(data,columns=['Body','Sub','Time'])\n",
    "x['Time'] = x['Time'].map(\n",
    "        lambda t: dt.datetime.fromtimestamp(t))\n",
    "x[\"Time\"] = pd.to_datetime(x[\"Time\"])\n",
    "x.sort_values('Time',ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = api.search_submissions(limit=5, sort='desc', sort_type='num_comments', after='1d', subreddit='politics')\n",
    "for x in gen:\n",
    "    print(x.score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10ea401c57974083d72007c9f9dc3837b0d2be6d72a3c23504e3a619fd0fed26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
